{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bbff264c",
   "metadata": {},
   "source": [
    "# Approximation de la finesse maximale avec un _réseau neuronal convolutif_\n",
    "\n",
    "#### \n",
    "__Auteur__ : _Ilyas Baktache_  \n",
    "__Année__ : 2023\n",
    "_Université de Sherbrooke_\n",
    " \n",
    "__Objectif__ :  On cherche à approximer la finesse maximale de profil d'aile d'avion en fonction du nombre de Reynolds et du nombre de Mach à l'aide de modèles de réseau de neurone convolutif.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c79ffb0d",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Dans ce notebook, on cherche à développer un outil qui permet d’approximer les performances aérodynamiques d’un profil pour plusieurs raisons :\n",
    "* Obtenir quasi-instantanément des données de finesse de profils.\n",
    "* Éviter d’utiliser les logiciels comme Xfoil qui sont complexes (à faire marcher) et lents.\n",
    "\n",
    "Dans ce but, on s’intéresse à la notion de réseau neuronal convolutif ou CNN. C’est une classe de réseaux neuronaux artificiels qui sont souvent utilisés pour de l’analyse d’imagerie visuelle comme on peut le voir sur cet article [13] qui compare divers modèle de CNN pour la reconnaissance d’expression faciale. Malgré le fait que les CNN soient principalement utilisés pour de l’analyse d’imagerie , on retrouve diverses applications des CNN pour des problèmes 1D qui se rapprochent du nôtre :\n",
    "* Reconnaissance d’activité humaine : [9], [3]\n",
    "* Approximation d’une fonction 1D : [4]\n",
    "\n",
    "Ainsi, on souhaite étudier la précision de différents modèles de CNN appliqué à notre problème : l’approximation de finesse d’un profil d’aile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38de345f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Librairies\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np\n",
    "from itertools import combinations_with_replacement\n",
    "# Plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Custom\n",
    "from data.pre_process import *\n",
    "\n",
    "from data.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bc6358c9",
   "metadata": {},
   "source": [
    "## Pré-traitement des données\n",
    "\n",
    "On commence par importer les données de finesse de profils d’aile. Ces données sont issues du logiciel Xfoil et sont disponibles sur le site de l’Université de Sherbrooke [1]. On importe les données dans un dataframe pandas.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c36fd39f",
   "metadata": {},
   "source": [
    "### Visualisation des données\n",
    "\n",
    "On commence par visualiser les données de finesse de profils d’aile en fonction du nombre de Reynolds et du nombre de Mach. On peut voir que les données sont très dispersées et que la finesse maximale est très variable en fonction du nombre de Reynolds et du nombre de Mach.\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31efe6ef",
   "metadata": {},
   "source": [
    "### Préparation des données\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "264c963e",
   "metadata": {},
   "source": [
    "### Etiquetage des données\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "581ecfd8",
   "metadata": {},
   "source": [
    "## Modèles de CNN\n",
    "\n",
    "On commence par définir les modèles de CNN que l’on va utiliser. On utilise la librairie Keras qui est une librairie de machine learning qui permet de créer des modèles de réseaux de neurones. On utilise la version 2.2.4 de Keras qui est compatible avec TensorFlow 2.0.0. \n",
    "\n",
    "### Modèle 1\n",
    "\n",
    "On commence par définir le premier modèle de CNN. Ce modèle est composé de 3 couches de convolution, 2 couches de pooling et 2 couches de neurones entièrement connectés. On utilise la fonction d’activation ReLU pour les couches de convolution et de pooling et la fonction d’activation softmax pour la couche de sortie. On utilise :\n",
    "* Pour la fonction de perte : la fonction d’erreur categorical_crossentropy car c'est un problème de classification multiclasse\n",
    "* l’optimisation des paramètres du modèle : l’optimiseur Adam car il est plus rapide que l’optimiseur SGD et il donne de meilleurs résultats que l’optimiseur RMSprop\n",
    "* Pour la métrique de performance : la précision car c’est un problème de classification multiclasse\n",
    "\n",
    "### Modèle 2\n",
    "\n",
    "On définit le deuxième modèle de CNN. Ce modèle est composé de 4 couches de convolution, 2 couches de pooling et 2 couches de neurones entièrement connectés. On utilise la fonction d’activation ReLU pour les couches de convolution et de pooling et la fonction d’activation softmax pour la couche de sortie. On utilise :\n",
    "* Pour la fonction de perte : la fonction d’erreur categorical_crossentropy car c'est un problème de classification multiclasse\n",
    "* l’optimisation des paramètres du modèle : l’optimiseur Adam car il est plus rapide que l’optimiseur SGD et il donne de meilleurs résultats que l’optimiseur RMSprop\n",
    "* Pour la métrique de performance : la précision car c’est un problème de classification multiclasse\n",
    "\n",
    "### Modèle 3\n",
    "\n",
    "On définit le troisième modèle de CNN. Ce modèle est composé de 5 couches de convolution, 2 couches de pooling et 2 couches de neurones entièrement connectés. On utilise la fonction d’activation ReLU pour les couches de convolution et de pooling et la fonction d’activation softmax pour la couche de sortie. On utilise :\n",
    "* Pour la fonction de perte : la fonction d’erreur categorical_crossentropy car c'est un problème de classification multiclasse\n",
    "* l’optimisation des paramètres du modèle : l’optimiseur Adam car il est plus rapide que l’optimiseur SGD et il donne de meilleurs résultats que l’optimiseur RMSprop\n",
    "* Pour la métrique de performance : la précision car c’est un problème de classification multiclasse\n",
    "\n",
    "### Modèle 4\n",
    "\n",
    "On définit le quatrième modèle de CNN. Ce modèle est composé de 6 couches de convolution, 2 couches de pooling et 2 couches de neurones entièrement connectés. On utilise la fonction d’activation ReLU pour les couches de convolution et de pooling et la fonction d’activation softmax pour la couche de sortie. On utilise :\n",
    "* Pour la fonction de perte : la fonction d’erreur categorical_crossentropy car c'est un problème de classification multiclasse\n",
    "* l’optimisation des paramètres du modèle : l’optimiseur Adam car il est plus rapide que l’optimiseur SGD et il donne de meilleurs résultats que l’optimiseur RMSprop\n",
    "* Pour la métrique de performance : la précision car c’est un problème de classification multiclasse\n",
    "\n",
    "### Hyperparamètres\n",
    "\n",
    "Concernant les hyperparamètres, on cherche à determiner lesquelle permettent d'avoir la meilleur précision possible. Ainsi, on va tester plusieurs combinaisons d'hyperparamètres pour chaque modèle de CNN. On va tester les hyperparamètres suivants :\n",
    "* Le nombre d'époques\n",
    "* La taille du batch\n",
    "* Le nombre de couches de convolution\n",
    "* Le nombre de noyaux de convolution\n",
    "* Le nombre de couches de pooling\n",
    "* Le nombre de couches de neurones entièrement connectés\n",
    "* La fonction d'activation\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "675a2eca",
   "metadata": {},
   "source": [
    "## Entraînement des modèles\n",
    "\n",
    "\n",
    "\n",
    "On entraîne les modèles de CNN sur les données de finesse de profils d’aile. On utilise la fonction fit de Keras qui permet d’entraîner le modèle sur les données d’entraînement. On utilise 10% des données pour la validation croisée. On entraîne les modèles pendant 1000 époques. On utilise les callbacks suivants: \n",
    "\n",
    "* EarlyStopping : On utilise la fonction de Keras qui permet d’arrêter l’entraînement du modèle si la précision sur les données de validation n’augmente plus pendant 10 époques. Elle permet d’éviter le sur-apprentissage.\n",
    "* On utilise la fonction ModelCheckpoint de Keras qui permet de sauvegarder le modèle qui a la meilleure précision sur les données de validation. \n",
    "* On utilise la fonction TensorBoard de Keras qui permet de visualiser les courbes de perte et de précision sur les données d’entraînement et de validation pendant l’entraînement du modèle. \n",
    "* On utilise la fonction LearningRateScheduler de Keras qui permet de réduire le taux d’apprentissage de 10% à chaque 10 époques. \n",
    "* On utilise la fonction ReduceLROnPlateau de Keras qui permet de réduire le taux d’apprentissage de 10% si la précision sur les données de validation n’augmente pas pendant 10 époques. \n",
    "* On utilise la fonction CSVLogger de Keras qui permet d’enregistrer les courbes de perte et de précision sur les données d’entraînement et de validation pendant l’entraînement du modèle dans un fichier CSV. \n",
    "\n",
    "Ensuite, pour l'analyse des résultats, on va utiliser les fonctions suivantes :\n",
    "* On utilise la fonction confusion_matrix de scikit-learn qui permet de calculer la matrice de confusion. \n",
    "* On utilise la fonction classification_report de scikit-learn qui permet de calculer le rapport de classification. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8866ac5",
   "metadata": {},
   "source": [
    "### Expérience sur les hyper-paramètres\n",
    "\n",
    "On va maintenant tester les hyperparamètres pour chaque modèle de CNN comme définis plus haut. On extrait alors les résultats par modèle:\n",
    "\n",
    "* Modèle 1 :\n",
    "    * Nombre d'époques : 100\n",
    "    * Taille du batch : 32\n",
    "    * Nombre de couches de convolution : 3\n",
    "    * Nombre de noyaux de convolution : 32\n",
    "    * Fonction d'activation : ReLU\n",
    "* Modèle 2 :\n",
    "    * Nombre d'époques : 100\n",
    "    * Taille du batch : 32\n",
    "    * Nombre de couches de convolution : 4\n",
    "    * Nombre de noyaux de convolution : 32\n",
    "    * Fonction d'activation : ReLU\n",
    "* Modèle 3 :\n",
    "    * Nombre d'époques : 100\n",
    "    * Taille du batch : 32\n",
    "    * Nombre de couches de convolution : 5\n",
    "    * Nombre de noyaux de convolution : 32\n",
    "    * Fonction d'activation : ReLU\n",
    "* Modèle 4 :\n",
    "    * Nombre d'époques : 100\n",
    "    * Taille du batch : 32\n",
    "    * Nombre de couches de convolution : 6\n",
    "    * Nombre de noyaux de convolution : 32\n",
    "    * Fonction d'activation : ReLU\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a4aca82f",
   "metadata": {},
   "source": [
    "## Résultats\n",
    "\n",
    "On affiche alors dans la partie suivante les résultats de ces modèles avec les meilleurs hyperparamètres.\n",
    "\n",
    "### Modèle 1\n",
    "\n",
    "On affiche les courbes de perte et de précision sur les données d’entraînement et de validation pendant l’entraînement du modèle. On affiche aussi la matrice de confusion et le rapport de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e66c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "read_test.show_results(1,0,50000,plot_loss=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fe7e50fa",
   "metadata": {},
   "source": [
    "### Modèle 2\n",
    "\n",
    "On affiche les courbes de perte et de précision sur les données d’entraînement et de validation pendant l’entraînement du modèle. On affiche aussi la matrice de confusion et le rapport de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a06c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test.show_results(2,0,50000,plot_loss=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ef56a61d",
   "metadata": {},
   "source": [
    "### Modèle 3\n",
    "\n",
    "On affiche les courbes de perte et de précision sur les données d’entraînement et de validation pendant l’entraînement du modèle. On affiche aussi la matrice de confusion et le rapport de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadabb2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test.show_results(3,0,50000,plot_loss=True)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a15ad1de",
   "metadata": {},
   "source": [
    "### Modèle 4\n",
    "\n",
    "On affiche les courbes de perte et de précision sur les données d’entraînement et de validation pendant l’entraînement du modèle. On affiche aussi la matrice de confusion et le rapport de classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b605c9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_test.show_results(4,0,50000,plot_loss=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "41982d8aa74645e741decf136ad0e30c046066c2dbc8aeff96601c91f9a96cfc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
